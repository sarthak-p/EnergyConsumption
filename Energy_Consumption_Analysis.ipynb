{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8811277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthak/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3400: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries in joined: 0\n",
      "NaN coordinates in gdf: False\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNaN coordinates in gdf:\u001b[39m\u001b[39m\"\u001b[39m, check_for_nan_coords([gdf]))\n\u001b[0;32m--> 131\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNaN coordinates in land_use:\u001b[39m\u001b[39m\"\u001b[39m, check_for_nan_coords(land_use))\n\u001b[1;32m    134\u001b[0m \u001b[39m# Combine the results\u001b[39;00m\n\u001b[1;32m    135\u001b[0m land_use \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(land_use_joined)\n",
      "Cell \u001b[0;32mIn[23], line 126\u001b[0m, in \u001b[0;36mcheck_for_nan_coords\u001b[0;34m(gdfs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m gdf \u001b[39min\u001b[39;00m gdfs:\n\u001b[1;32m    125\u001b[0m     \u001b[39mfor\u001b[39;00m geom \u001b[39min\u001b[39;00m gdf\u001b[39m.\u001b[39mgeometry:\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mif\u001b[39;00m geom \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misnan(geom\u001b[39m.\u001b[39;49mxy)\u001b[39m.\u001b[39many():\n\u001b[1;32m    127\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/shapely/geometry/base.py:212\u001b[0m, in \u001b[0;36mBaseGeometry.xy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mxy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[39m\"\"\"Separate arrays of X and Y coordinate values\"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fiona\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data file\n",
    "df = pd.read_csv('comed_201910.csv')\n",
    "\n",
    "# Filter out only residential accounts\n",
    "df_residential = df[df['service_name'].str.contains('residential', case=False, na=False)]\n",
    "\n",
    "# Filter for one day, ex. 2019-10-01\n",
    "desired_date = '2019-10-01'\n",
    "df_residential = df_residential[df_residential['date_time'].str.contains(desired_date)]\n",
    "\n",
    "# Convert the time from HH:MM to seconds past since the beginning of the day\n",
    "df_residential['date_time'] = pd.to_datetime(df_residential['date_time'])\n",
    "df_residential['seconds_past'] = df_residential['date_time'].dt.hour * 3600 + df_residential['date_time'].dt.minute * 60\n",
    "\n",
    "# Aggregate data to find time of maximum energy consumption for each zip code\n",
    "df_grouped = df_residential.groupby('zip5')['energy'].idxmax()\n",
    "peak_times = df_residential.loc[df_grouped, ['zip5', 'energy', 'seconds_past']]\n",
    "peak_times.columns = ['zip_code', 'peak_energy_value', 'peak_energy_time']\n",
    "\n",
    "# Load the geojson file\n",
    "gdf = gpd.read_file('Chicago_ZC.geojson')\n",
    "\n",
    "# Convert the 'GEOID20' column to integer for join operation\n",
    "gdf['GEOID20'] = gdf['GEOID20'].astype(int)\n",
    "\n",
    "# Merge the peak_times DataFrame with the gdf GeoDataFrame based on 'zip_code'\n",
    "gdf = gdf.merge(peak_times, left_on='GEOID20', right_on='zip_code', how='left')\n",
    "\n",
    "# Convert the geometries to a projected CRS\n",
    "gdf = gdf.to_crs('EPSG:3857')\n",
    "\n",
    "# Calculate the centroid of each polygon\n",
    "gdf['centroid'] = gdf['geometry'].centroid\n",
    "\n",
    "# Convert back to geographic for lat/long coordinates\n",
    "gdf = gdf.to_crs('EPSG:4269')\n",
    "\n",
    "# Convert the centroid to latitude and longitude coordinates\n",
    "gdf['Lat_centroid'] = gdf['centroid'].y\n",
    "gdf['Long_centroid'] = gdf['centroid'].x\n",
    "\n",
    "# Keep only the desired columns\n",
    "gdf = gdf[['zip_code', 'peak_energy_value', 'peak_energy_time', 'Lat_centroid', 'Long_centroid']]\n",
    "\n",
    "# Convert 'zip_code' to int, handling NaN values which cannot be converted to int\n",
    "gdf['zip_code'] = gdf['zip_code'].astype('Int64')\n",
    "\n",
    "gdf = gdf.dropna()\n",
    "\n",
    "# Convert back to GeoDataFrame\n",
    "gdf['geometry'] = gpd.points_from_xy(gdf.Long_centroid, gdf.Lat_centroid)\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "gdf.set_crs(\"EPSG:4269\", inplace=True)\n",
    "\n",
    "# Load the land use shapefile into a GeoDataFrame\n",
    "gdb_folder = 'Landuse2018_CMAP_v1.gdb'\n",
    "\n",
    "# Function to load the data in chunks, using only the necessary columns\n",
    "def load_data(gdb_folder, layer):\n",
    "    # Residential land use codes\n",
    "    residential_codes = ['1000', '1100', '1110', '1111', '1112', '1130', '1140', '1150', '1151']\n",
    "    \n",
    "    with fiona.Env():\n",
    "        with fiona.open(gdb_folder, layer=layer) as src:\n",
    "            # Read all records\n",
    "            records = [{'geometry': f['geometry'], 'LANDUSE': f['properties']['LANDUSE']} \n",
    "                       for f in src if f is not None and 'geometry' in f]\n",
    "            \n",
    "            df = pd.DataFrame.from_records(records)\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=src.crs)\n",
    "\n",
    "    # Filter the GeoDataFrame to include only desired land use categories\n",
    "    gdf = gdf[gdf['LANDUSE'].isin(residential_codes)]\n",
    "\n",
    "    # Now split into chunks\n",
    "    gdfs = [gdf[i:i+chunksize] for i in range(0, gdf.shape[0], chunksize)]\n",
    "    return gdfs\n",
    "\n",
    "chunksize = 50000\n",
    "\n",
    "land_use = load_data(gdb_folder, 'Landuse2018_Dissolved_v1')\n",
    "\n",
    "# Convert the land use data to the same CRS as the zip code data\n",
    "land_use = [lu_gdf.to_crs(gdf.crs) for lu_gdf in land_use]\n",
    "\n",
    "# Initialize an empty list to hold the results\n",
    "land_use_joined = []\n",
    "\n",
    "for lu_gdf in land_use:\n",
    "    # Repair invalid geometries\n",
    "    lu_gdf['geometry'] = lu_gdf.geometry.buffer(0)\n",
    "    \n",
    "    # Verify validity of geometries\n",
    "    #print(lu_gdf['geometry'].is_valid.sum())\n",
    "\n",
    "    # Check the coordinate systems of both GeoDataFrames\n",
    "    #print(\"Land use CRS:\", lu_gdf.crs)\n",
    "    #print(\"Zip code CRS:\", gdf.crs)\n",
    "\n",
    "    # Perform a spatial join to associate each land use parcel with its corresponding zip code\n",
    "    # After the spatial join\n",
    "    joined = gpd.sjoin(lu_gdf, gdf[['geometry', 'zip_code']], how='left', op='intersects')\n",
    "    joined['geometry'] = joined.geometry.buffer(0)\n",
    "    print(\"Invalid geometries in joined:\", (joined['geometry'].is_valid == False).sum())\n",
    "\n",
    "\n",
    "    # Print the number of non-null zip codes in the joined dataframe\n",
    "    #print(joined['zip_code'].notna().sum())\n",
    "\n",
    "    land_use_joined.append(joined)\n",
    "\n",
    "def check_for_nan_coords(gdfs):\n",
    "    for gdf in gdfs:\n",
    "        for geom in gdf.geometry:\n",
    "            if geom is not None and np.isnan(geom.xy).any():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "print(\"NaN coordinates in gdf:\", check_for_nan_coords([gdf]))\n",
    "print(\"NaN coordinates in land_use:\", check_for_nan_coords(land_use))\n",
    "\n",
    "\n",
    "# Combine the results\n",
    "land_use = pd.concat(land_use_joined)\n",
    "\n",
    "land_use = land_use.to_crs('EPSG:3857')\n",
    "\n",
    "# Calculate the area of each land use type in each zip code\n",
    "land_use['area'] = land_use.geometry.area\n",
    "\n",
    "land_use = land_use.to_crs(gdf.crs)\n",
    "\n",
    "# Summarize land use area by land use type and zip code\n",
    "land_use_summary = land_use.groupby(['zip_code', 'LANDUSE']).area.sum().unstack().reset_index()\n",
    "\n",
    "# Fill NA values with 0 (no land of that type in the zip code)\n",
    "land_use_summary.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the total area of each zip code\n",
    "total_area = land_use_summary.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Normalize the land use areas by the total area of each zip code\n",
    "for col in land_use_summary.columns[1:]:\n",
    "    land_use_summary[col] = land_use_summary[col] / total_area\n",
    "\n",
    "# Join the land use data with the original DataFrame\n",
    "gdf = gdf.merge(land_use_summary, on='zip_code', how='left')\n",
    "\n",
    "# Load the data\n",
    "data = gdf\n",
    "\n",
    "# Split the data into X and Y variables\n",
    "# Include all columns as input features except 'peak_energy_time' and 'geometry'\n",
    "feature_cols = ['zip_code', 'peak_energy_value', 'Lat_centroid', 'Long_centroid'] + list(land_use_summary.columns[1:])\n",
    "X = data[feature_cols]\n",
    "Y = data['peak_energy_time']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# *** THIS CODE USES RANDOMIZED SEARCH AND IS LESS COMPUTATIONALLY EXPENSIVE THAN GRID SEARCH *** \n",
    "\n",
    "# Refining hyperparameters for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': list(range(135, 145)),  # Focusing more on 140\n",
    "    'max_depth': [6],  # Optimal value from the last search\n",
    "    'learning_rate': np.linspace(0.045, 0.055, 20),  # Focusing more around 0.049\n",
    "    'gamma': np.linspace(0.33, 0.37, 20),  # Focusing more around 0.35\n",
    "    'colsample_bytree': [1.0],  # Optimal value from the last search\n",
    "    'subsample': np.linspace(0.80, 0.85, 20)  # Focusing more around 0.82\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "xgb_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=xgb_param_grid, n_iter=100, cv=5, random_state=42)\n",
    "xgb_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best XGBoost Parameters:\", xgb_search.best_params_)\n",
    "print(\"Best XGBoost Score:\", xgb_search.best_score_)\n",
    "\n",
    "# Refining hyperparameters for RandomForest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': list(range(235, 245)),  # Focusing more around 241\n",
    "    'max_depth': list(range(20, 23)),  # Focusing more around 21\n",
    "    'min_samples_split': [8],  # Optimal value from the last search\n",
    "    'min_samples_leaf': [1],  # Optimal value from the last search\n",
    "    'bootstrap': [True]  # Optimal value from the last search\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf_search = RandomizedSearchCV(estimator=rf_model, param_distributions=rf_param_grid, n_iter=100, cv=5, random_state=42)\n",
    "rf_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best RandomForest Parameters:\", rf_search.best_params_)\n",
    "print(\"Best RandomForest Score:\", rf_search.best_score_)\n",
    "\n",
    "# Check if land use data is included in the training set\n",
    "land_use_columns = [col for col in X_train.columns if 'LANDUSE' in col]\n",
    "if not land_use_columns:\n",
    "    print(\"No land use data included in the training set.\")\n",
    "else:\n",
    "    print(f\"Land use data included in the training set: {land_use_columns}\")\n",
    "\n",
    "# Check for missing values in land use data\n",
    "missing_values = X_train[land_use_columns].isnull().sum()\n",
    "print(\"Missing values in land use data:\\n\", missing_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
